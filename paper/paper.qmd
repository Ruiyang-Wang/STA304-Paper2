---
title: "2024 USA Election Prediction"
author: 
  - Ruiyang Wang
thanks: "Code and data are available at: [https://github.com/Ruiyang-Wang/STA304-Paper2.git)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

install.packages("knitr")
install.packages("kableExtra")
install.packages("readr")
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(readr)
library(knitr)
library(kableExtra)
library(MASS)

```


# Introduction

The 2024 U.S. presidential election has attracted unprecedented attention, with voters facing a range of pressing issues, from economic uncertainty to social policy and global affairs. As the election campaign intensifies, polling data has become a key tool for understanding public sentiment and predicting potential outcomes. However, it is challenging to accurately interpret the data due to a variety of factors that can influence poll results, including sample size, pollster methodology, and the demographics of respondents. This article aims to provide a comprehensive analysis of polling data(@US2024)

To construct this analysis, we first explored how the sample size affected the support of the top five candidates in this race - Joe Biden, Kamala Harris, Donald Trump, Robert Kennedy Jr., and Jill Stein. Given that some candidates, notably Trump and Harris, have larger voter bases, it is necessary to determine whether changes in sample size are correlated with fluctuations in candidate support. Using sample sizes for simple linear regression (SLR) and logarithmic transformations to address model assumptions violations, we confirm that while sample sizes do affect support percentages, the effect is limited due to the small R-squared values.

After the initial analysis, we move on to the main analysis: building multiple linear regression (MLR) models for each of the first five candidate. By combining multiple predictor variables, we aim to develop more robust models that capture the nuances of voter support patterns. These MLR models allow us to predict support over time, and a visual representation of these projections shows trends throughout the election period.

This study highlights not only the importance of sample size in polling, but also the predictive power of more comprehensive models in capturing voter sentiment. The findings reveal the limitations and potential of poll analysis as an election forecasting tool, helping to better understand the dynamics of public opinion ahead of the 2024 presidential election.

This paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR]to generate analysis. Our data [@US2024] provides a detailed look at voter support trends for the candidates in 2024 US election. By exploring this data, we aim to gain insights into how sample size and polling quality impact reported support percentages.To enhance our approach, we follow principles from Telling Stories with Data [@tellingstories], which emphasizes clear and effective communication of data insights.We employ a variety of visualization techniques and statistical models to ensure that our findings are accessible and well supported. With these approaches, we highlight the nuances of poll data analysis, particularly in terms of sample size effects and model accuracy, ultimately helping to get a clearer picture of voter sentiment as we approach the 2024 election.

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
# Load the candidate models
candidate_models <- readRDS("~/STA304 Paper2/models/candidate_models_top_5.rds")

# Plot Residuals vs Fitted for each candidate
for (candidate in names(candidate_models)) {
  # Extract the model
  model <- candidate_models[[candidate]]
  
  # Create the Residuals vs Fitted plot
  plot(model, which = 1, main = paste("Residuals vs Fitted -", candidate))
}

```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "final prediction graph"
#| warning: false

# Load the predicted support data
combined_predictions <- readRDS("~/STA304 Paper2/models/predicted_support_top_5.rds")

# Create the final prediction graph
ggplot(combined_predictions, aes(x = end_date, y = predicted_pct, color = answer, group = answer)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Predicted Support Percentage Over Time for Top 5 Candidates", 
       x = "Date", y = "Predicted Support Percentage (%)") +
  scale_x_date(limits = c(as.Date("2024-01-01"), as.Date("2024-11-05"))) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))  # Center the title

```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


